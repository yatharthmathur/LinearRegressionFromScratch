{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='RED' size='6'><b>MACHINE LEARNING : Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.jpeg\" alt=\"Linear Regression Model\" height='400' width='400' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Linear Regression is the most basic approach of modelling used in predictive analysis.\n",
    "<br>The overall idea of regression is to examine two things:<br>(1) does a set of predictor variables do a good job in predicting an outcome (dependent) variable?  <br>(2) Which variables in particular are significant predictors of the outcome variable, and in what way do they impact the outcome variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font size='3'>Some basic concepts : </font><br><br>\n",
    "    Supervised learning </b>: Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.<br><br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font size='3'>Model Representation</font> <br><br></b>\n",
    "    First, the goal of most machine learning algorithms is to construct a model: a hypothesis that can be used to estimate Y based on X. The hypothesis, or model, maps inputs to outputs.<br><br>\n",
    "    The hypothesis is usually presented as :\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='5' align=left>$$h_\\theta(x^i) = \\theta_0 + x^i\\theta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to find the values of <font size='3'>ùúÉ</font>0 and <font size='3'>ùúÉ</font>1 such that the cost(h(x)) for each ith test sample(x^i) has the minimum mean difference from respective  training example y^i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This boils down to minimization of the cost function for m training samples as follows : \n",
    "\n",
    "<font size='5'>$$\\frac{1}{2m} {\\textstyle \\sum^m_i} (h_\\theta(x)_i - y_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size='5' color='red'>IMPLEMENTATION OF LINEAR REGRESSION FOR MACHINE LEARNING IN PYTHON</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='5'><b>STEP 1 </b>: Importing the appropriate libraries.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a self explanatory code. We're basically importing all the necessary libraries needed for the implementation of Linear Regression model, that is numpy for hard mathematics and matplotlib for plotting graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='5'><b>STEP 2 </b>: Reading data and creating the required vectors/matrices</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([-1.0, -2.0, -3.0, -4.0, -5.0])\n",
    "Y = data\n",
    "X = [0.0, 1.0, 2.0, 3.0, 4.0]\n",
    "x_train = [5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "y_train = [-6.0, -7.0, -8.0, -9.0, -10.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically this data represents a line y = -x-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='5'><b>STEP 3 </b>: Making the cost function</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#let the prediction be Y = W * X + b, the answer should be y= -1*X + -1\n",
    "W = 0.3\n",
    "b = -0.3\n",
    "ones = np.array([1.0,1.0,1.0,1.0,1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(W,b):\n",
    "    pred = np.dot(X,W) + np.dot(b,ones)\n",
    "    return (1/10.0)*np.sum(np.square(pred-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.135000000000001"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(-0.3,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know the current cost is really high, optimally we would want the parameters W and b such that the cost is 0 as follow. So we have to get W = -1 and b = -1 for our model to work accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(-1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='5'><b>STEP 4 </b>: Gradient Descent to optimize W and b</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GradientDescent(X,Y,W,b,a,i):\n",
    "    cost_history = np.zeros(i)\n",
    "    W_history = np.zeros(i)\n",
    "    b_history = np.zeros(i)\n",
    "    w1 = W\n",
    "    b1 = b\n",
    "    for it in range(i):\n",
    "        W_history[it] = W\n",
    "        b_history[it] = b\n",
    "        pred = np.dot(X,W) + np.dot(b,ones)\n",
    "        w1 = W - (1/m)*a*np.dot(np.transpose(X),(pred-Y))\n",
    "        b1 = b - (1/m)*a*np.sum(pred-Y)\n",
    "        cost_history[it] = cost(w1,b1)\n",
    "        W = w1\n",
    "        b = b1\n",
    "        \n",
    "    return W, b, W_history, b_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b, W_h, b_h = GradientDescent(X,Y,W,b,0.1,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have optimized our parameters W and b let's see how close they are to our required value : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.000000000970514 -0.9999999972332775\n",
      "Cost on the current parameters =  1.2827829817897735e-18\n"
     ]
    }
   ],
   "source": [
    "print(W,b)\n",
    "print(\"Cost on the current parameters = \", cost(W,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that it is pretty close. Now we can use this code to determine any univariate linear regression problem with a very few adjustments. Let's see how it predicts :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.dot(W,x_train) + np.dot(ones,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6.          -7.          -8.          -9.         -10.00000001]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the accuracy on the given test data : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error=np.mean(np.sum(np.square(pred-y_train)))\n",
    "mean_squared_accuracy=1-mean_squared_error\n",
    "print(\"Accuracy = \", mean_squared_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
